\chapter{Debugging support}

\begin{quote}
  \textit{Debugging is twice as hard as writing the code in the first place.
    Therefore, if you write the code as cleverly as possible, you are, by
    definition, not smart enough to debug it.}\begin{flushright}
    \tiny{Brian W. Kernighan}
  \end{flushright}
\end{quote}

We mentioned in the first chapter that to debug programs written in a high
level programming languages, we need the compiler to emit debugging
information. However, we can still debug programs at the assembly level. This
can still be useful, for example for reverse engineering. And, as was already
hinted, source level debugging is built upon assembly debugging. In this
chapter, we will describe at which level and what kind of debugging support is
provided. First, we will mention which kind of mechanism the CPU itself offers.
Going one step higher, we will talk about the API that various operating
systems provide. Finally, we'll discuss how are compilers and debuggers able to
allow us to debug source code although the programs are still machine code
programs. 

\section{Support on CPU level} In the first chapter it was said that the CPU
can only execute machine code which is made of instructions and that it has
certain registers. Which instructions and registers the CPU has can differ from
CPU to CPU. This is specified by \textit{Instruction Set Architecture} (ISA)
\cite{aps-isa}. It is an abstract interface between the hardware and the lowest
level software (machine code). It contains all information needed to write a
program in machine code. In general, ISA specifies the following: 
\begin{itemize}
    \item Set of machine code instructions - Specifies instructions the ISA has
        and what operands each instruction has.
    \item Register set - Which registers the ISA has\footnote{Strictly speaking
        ISA doesn't have to use registers. It's possible to use only stack or
        accumulator, but most used ISAs use registers, so we'll ignore those
        architectures. }.   
    \item Addressing modes - Possible methods to refer to memory or register. 
\end{itemize} There are other specifications,
however, they are not relevant to this thesis. For each instruction and operand
it is specified how they should be encoded into binary. CPU then
\textit{implements} some ISA. If two different CPUs implement the same ISA then
they should be able to run the same machine code program. For example, most PC
use the \textit{x86} architecture \cite{aps-isa}, although the ARM architecture
is also seeing use in personal computers, for example, the Apple Sillicon is of
ARM architecture.

The x86 architecture is so called \textit{Complex Instruction Set Architecture}
(CISC). It contains many instructions that do many things at once, have varying
lengths, and take multiple clock cycles to complete \cite{intel-manual}. On the
other hand, the ARM architecture is \textit{Reduced Instruction Set
Architecture} (RISC). The number of instructions is smaller, they are intended
to be small building blocks from which complex operations may be created by
using many of them. Each instruction in RISC also has the same length. Both
architectures have their pros and cons, although some literature suggests that
in modern days the choice of architecture is irrelevant if one is only
considering performance and power consumption \cite{riscvscisc1, riscvscisc2}.
Unless specified otherwise the rest of this chapter will be talking about x86.
This is because T86 \todo{ref} is loosely based on x86, so it is most relevant
for us.

In the first chapter, we briefly mentioned that machine code programs can
instead be written in Assembly language. Assembly is almost 1:1 mapping to
machine code. When showing programs, we will show them in assembly. In figure
\ref{fig:assembly-example2}, we present another example of a program that was
compiled from C to assembly of the x86 architecture. As seen, instructions have
various operands. Most often registers (\texttt{RBP, RSP, EAX}), memory
(\texttt{[rbp-4]} is reference to memory at address which is in register
\texttt{rbp} minus $4$), or labels (like \texttt{L2}). Labels are not part of
machine code, instead memory address has to be provided. This is a small part
where assembly and machine code differ. For a detailed overview of the x86
instruction set see \cite{intel-manual}.

\begin{figure}\label{fig:assembly-example2}
    \begin{lstlisting}
max:
    push    rbp
    mov     rbp, rsp
    mov     QWORD PTR [rbp-24], rdi
    mov     DWORD PTR [rbp-28], esi
    mov     rax, QWORD PTR [rbp-24]
    mov     eax, DWORD PTR [rax]
    mov     DWORD PTR [rbp-4], eax
    mov     DWORD PTR [rbp-8], 1
    jmp     .L2
.L3:
    mov     eax, DWORD PTR [rbp-8]
    cdqe
    lea     rdx, [0+rax*4]
    mov     rax, QWORD PTR [rbp-24]
    add     rax, rdx
    mov     eax, DWORD PTR [rax]
    cmp     DWORD PTR [rbp-4], eax
    cmovge  eax, DWORD PTR [rbp-4]
    mov     DWORD PTR [rbp-4], eax
    add     DWORD PTR [rbp-8], 1
.L2:
    mov     eax, DWORD PTR [rbp-8]
    cmp     eax, DWORD PTR [rbp-28]
    jl      .L3
    mov     eax, DWORD PTR [rbp-4]
    pop     rbp
    ret
    \end{lstlisting}
    \caption{Compiled C program with GCC 9.4 compiler as x86 assembly.}
\end{figure}

\subsection{Registers}\label{subsection:registers}

The x86 architecture has a set of general purpose registers.
Some of these are
\begin{itemize}
    \item RAX - Accumulator for operands and results data,
    \item RCX - Counter for string and loop operations,
    \item RSP - Stack pointer,
    \item RBP - Pointer to data on the stack.
\end{itemize}
The names and number of general purpose registers change based on bit mode.
64-bit (also named x86-64) mode has 16 of them, while 32-bit has 8. The names
are more of a convention. It is not necessary to use RCX only for loop
operations. Although the \texttt{RSP} and \texttt{RBP} are called general
purpose they are often only used for pointing at the top of the stack, resp. to
the base of the stack. Stack is a special part of program memory, it mostly has
LIFO semantics\footnote{For example the \texttt{mov eax, DWORD PTR [rbp - 4]}
does not respect LIFO semantics, because it reads directly from the stack and
not from the top.} It can be used to store the intermediate result, arguments
to functions, return address, etc. This register is weird in a sense that it
has this very special purpose but is still considered part of the general
purpose registers~\cite{intel-manual}. One might use it for storing
calculations, but it would make the rest of the instructions that work with
stack behave unexpectedly.

The instruction pointer register (RIP on x86-64, EIP on x86) contains the
address of the current instruction to be executed. As we mentioned in
Introduction \todo{ref}, programs are executed sequentially from top to bottom,
with certain instructions having the ability to change the control flow. When
an instruction gets executed, the size of the instruction will be added to the
value in RIP register. This will advance the instruction pointer to the next
instruction. Or, if the instruction changes the control flow, the value in the
instruction pointer will be changed to the destination of the instruction. The
register can also be changed directly.

Another interesting register is the \texttt{EFLAGS} register. The register
contains a group of flags, which can alter various behavior of the CPU, or the
CPU itself sets them as a result of some instruction. For example the
instruction \texttt{cmp} compares its two operands and if they are the same the
\textit{zero} flag in the \texttt{EFLAGS} register will be set.

\subsection{Interrupts}
An interrupt is a special request to the CPU to stop the execution of the
current program and to quickly react to the reason that caused the request
\cite{aps-interrupts}. An example of such event can be a keyboard press or
error in a program (division by zero). There are two main categories
\cite{intel-manual}
\begin{itemize}
    \item An \textbf{interrupt} is an asynchronous\footnote{Meaning that the
        interrupt may happen when another instruction is being processed (not
        on the CPU clock edge).} event that is typically triggered by an
        Input/Output (IO) device.
    \item An \textbf{exception}\footnote{Unfortunately, this term will become
        quite overloaded in this thesis.} is a synchronous event that is
        generated when the processor detects one or more predefined conditions
        when executing an instruction. These are further divided into three
        classes: faults, traps, and aborts.
\end{itemize}

When an interrupt or exception happens, the processor halts the execution of a
current program and switches to a specific interrupt handler. An interrupt
handler is just another sequence of instructions that gets executed when the
interrupt happens. It is supposed to handle the interrupt. An example of an
exception is the \texttt{INT3} instruction. When this instruction is executed
an interrupt is generated. This instruction is specifically meant to be used as
a breakpoint. We can supply code that will be responsible for handling the
breakpoint as the interrupt handler. However, on modern PCs, an Operating
System (OS) is governing the PC. Alas, we cannot touch the interrupt handler
directly. Instead, an OS is going to have to provide another layer of support
for debugging.

Recall the EFLAGS register mentioned in section \ref{subsection:registers}.
There is a special flag called the trap flag. When it is set, the CPU will
issue an interrupt after every executed instruction. This could be useful if we
wanted to inspect execution instruction by instruction.

% Page ~3644 in intel manual
The CPU may also contain special debug registers. The x86 has six of them,
named DR0 to DR7, with DR4 and DR5 being synonyms for DR6 and DR7 on most CPUs,
otherwise they are reserved anyway. CPU provides special breakpoints through
these registers. The first four registers contain address of the breakpoints.
The debug status register \texttt{DR6} contains debug conditions that were
sampled at the last debug interrupt. Lastly, the debug control register
\texttt{DR7} is used to enable and disable breakpoints and set breakpoint
conditions. The CPU then issues an interrupt when these breakpoints are hit.
They can be triggered on memory read and write, on only on instruction
execution \cite{intel-manual}.

\subsection{Superscalar CPUs}
Modern CPUs do not execute instructions strictly one by one. They instead use
\textit{pipelines} and \textit{out-of-order execution}. This means that they
can execute several instructions at once and can execute them in non sequential
order. The observable behaviour of the program has to be the same as if it was
run sequentially. The CPU has to be careful about which instruction it can run
in parallel and out of order. The execution of an instruction consist of
several stages, which together form an \textit{execution pipeline}. The stages
can be \textit{Fetch}, \textit{Decode}, \textit{Execute}, \textit{Memory}, and
\textit{Writeback}, this may vary depending on architecture, but the general
ideas behind it are the same. The instruction must pass all these stages to be
successfully executed. To maximize efficiency, all stages are occupied by an
instruction. This means that when instruction $x$ leaves fetch stage, it goes
to the decode stage and instruction $y$ is put into the fetch stage.

However, what if we received a conditional jump instruction? How to knoe which
instruction will be next? Will it be the one at the jump destination, or the
next one because the condition will not hold? CPUs deal with it in various ways
and try to predict the right branch. Sometimes however, the prediction fails
and the whole pipeline needs to be flushed. Same thing must happen when
interrupt happens. The execution changes to the interrupt handler. This makes
sense, because the instructions to now be executed are from the handler, so the
pipeline must be flushed. Also, if we hit the breakpoint, we want to make sure
that instructions before it were all executed and that none was executed after,
otherwise it would be very confusing for the user that tries to debug the
program.

\section{Operating system support}
Operating system is a layer between computer components (CPU, memory,
input/output devices, \dots) and software. It is responsible for handling all
those resources so programmers do not have to think about it \cite{modern-os,
os-concepts}. Managing resources is not only to make writing programs easier
but to make sure that they are safe from each other. Modern operating system
allows to run multiple programs at once (or at least offer the illusion that it
can) and they make sure that one program cannot overwrite data or otherwise
interfere with other programs. Normal programs run in so-called \textit{user
space}, which has limited capabilities. The kernel on the other hand runs in
\textit{kernel space}. It has full access to the hardware of the computer, can
use all instructions, can permit or mask interrupts, and so on.

However, if programs were limited to user space all the time they would be very
limited. Sometimes, they need to escape the confinement of the OS, for example,
to read a file or communicate with other processes. Operating systems provide
an interface through which the user space program can leverage a small part of
the kernel in form of system calls. They offer a way of requiring some service
from the OS. This API is often in form of C and C++
functions~\cite{os-concepts}. A part of these functions is a special
instruction, like \texttt{SYSCALL} on x86~\cite{intel-manual}, that switches
the mode to kernel space. The kernel has to check if the call is correct since
it will be executed in kernel space with full access.

The most used operating systems today are Microsoft Windows, Linux, and MacOS.
Linux and MacOS systems are somewhat similar, but Windows is very different.

\subsection{Linux}
Linux offers a special system call which is very handy for debugging. It is
called \texttt{ptrace} \cite{ptrace} - process trace. It has following
signature: \texttt{ptrace(PTRACE\_<COMMAND>, pid, ...)}. It takes a
\texttt{PTRACE\_COMMAND}, which specifies the behavior of the function (for
example \texttt{PTRACE\_SINGLESTEP}), pid of some process (presumably the
debugee) and some other parameters, depending on the \texttt{PTRACE\_COMMAND}
that was chosen\footnote{Peak API design!}. It allows to observe and control
the execution of another process, this process will be the debugee. In the
context of \texttt{ptrace}, we will instead use the word tracee for the
debugee, and tracer for the debugger, to be consistent with ptrace
documentation.

\texttt{ptrace} has many commands, here are some of the most important:
\begin{itemize}
    \item \texttt{PTRACE\_PEEKTEXT, PTRACE\_PEEKDATA} - Read tracee's memory,
    \item \texttt{PTRACE\_POKETEXT, PTRACE\_POKEDATA} - Write into tracee's
          memory,
    \item \texttt{PTRACE\_GETREGS} - Read tracee's register values,
    \item \texttt{PTRACE\_SETREGSET} - Modify tracee's register values,
    \item \texttt{PTRACE\_GETSIGINFO} - Retrieve information about the signal
                                        that caused tracee to stop,
    \item \texttt{PTRACE\_CONT} - Restart the stopped tracee process,
    \item \texttt{PTRACE\_SINGLESTEP} - Restart the stopped tracee but
          stop it after executing one instruction.
\end{itemize}

Linux however needs some way of notifying the debugger that the tracee
encountered a breakpoint, or that some other event requiring debugger attention
happened. To this end, \textit{signals} are used. They are in principle similar
to CPU interrupts. CPU interrupts are sent by the CPU and processed by the
operating system kernel. Signals are sent by the operating system kernel and
received by processes. They can also be sent by a process, that however happens
via system calls and so it goes through the kernel, so the statement still
stands. A signal is used in UNIX and Linux systems to notify a process that a
particular event has occurred \cite{os-concepts}.  When a process receives a
signal, it stops its execution and starts the execution of a signal handler.
There are various signal types. Most signals can have a custom signal handler
defined by the process. If no handler is defined then a default one is provided
by the OS. However, handlers for \texttt{SIGKILL} and \texttt{SIGSTOP} cannot
be changed \cite{signals}.

The reason for rising a signal can be \todo{Tady toho asi bude vic}
\begin{itemize}
    \item CPU Interrupt (Division by zero, Breakpoint hit),
    \item System call (\texttt{kill(pid, signal)}).
\end{itemize}

For example, the signal \texttt{SIGTERM} can be sent to a process to ask it
nicely to exit. The process can handle this request, for example, to save some
state before exiting. It can also however be completely ignored. For this, a
signal \texttt{SIGKILL} can be used, which cannot be handled, ignored, or
blocked.

To begin tracing a command \texttt{PTRACE\_ATTACH} may be used for an already
existing process, or a \texttt{fork} followed with a child calling
\texttt{PTRACE\_TRACEME} and typically \texttt{execve}. When the tracee is
being traced it will stop each time a signal is delivered to it, even if it
chooses to ignore said signal. The tracer will be notified that the tracee
received a signal at its next call to the \texttt{waitpid} function. When the
tracee is stopped the tracer can initiate various ptrace requests listed above
to inspect and change the state of the tracee \cite{ptrace}.

In the CPU chapter, we mentioned that there are debug instructions and that
they issue an interrupt. We do not directly handle the interrupt here. Even if
we wanted, user space programs can't do that. The Linux kernel handles this for
us and instead uses the signals as an abstraction. \todo{Include kernel code.}

\subsubsection{Debugger implementation}
Now, we have all the necessary building blocks to build a simple debugger on
the Linux operating system running on the x86 platform. Running a program under
the debugger is simple. In figure \ref{fig:debugger-init} you can see the
initialization of the debugger. It uses the fork-exec idiom. \texttt{fork}
system call creates an exact copy of the process as a child except the
following: process ID (PID) of the child is different. In the parent process,
PID of the child is returned. In the child, $0$ is returned. In the child, we
initiate the \texttt{PTRACE\_TRACEME} call, which indicates that this process
is to be traced by its parent. Then it calls \texttt{execve} system call, which
replaces this program with the one we want to debug. The execve causes a
\texttt{SIGTRAP} signal on completion because it is being traced
\cite{execve}.

The parent first issues a \texttt{waitpid} system call. This waits for the
child \texttt{execve} to finish. The debugger then has a chance to debug the
child immediately, because it is stopped. The \texttt{while} loop can then
request input from the user and act accordingly. The tracee can be continued by
\texttt{PTRACE\_CONT} command.

\begin{figure}\label{fig:debugger-init}
    \begin{minted}{c}
        pid_t pid = fork();
        if (pid == 0) {
            // Begin tracing
            ptrace(PTRACE_TRACEME, 0, NULL, NULL);
            // Replace the code with the intended tracee code
            execve(executable, argv, NULL);
        } else {
            int w;
            waitpid(pid, &w, 0);
            while(...) {
                // Main debugger loop
            }
        }
    \end{minted}
    \caption{Linux - Debugger initialization.}
\end{figure}

Reading and writing to memory is simple. The \texttt{PTRACE\_PEEKTEXT} and
\texttt{PTRACE\_POKETEXT} are used for this purpose. This call reads or writes
a word (32 or 64 bits, depending on the Linux variant) into tracees memory.
However, if we want to write an arbitrary amount of bytes, we have to work
around the word limitation. We need to write by blocks and for the last one we
have to pad the write with already existing data if the block size does not
divide the word size. Figure \ref{fig:write-read} is shown how to read and
write exactly one byte of memory at a given address.

\begin{figure}\label{fig:write-read}
    \begin{minted}{c}
uint8_t read_memory(pid_t pid, uint64_t address) {
    uint64_t data = ptrace(PTRACE_PEEKDATA, pid, address, NULL);
    return (uint8_t)data;
}

void write_memory(pid_t pid, uint64_t address, uint8_t data) {
    uint64_t old_data = ptrace(PTRACE_PEEKDATA, pid, address, NULL);
    uint64_t new_data = (old_data & ~0xFF) | data;
    ptrace(PTRACE_POKEDATA, pid, address, new_data);
}
    \end{minted}
    \caption{Linux - Reading and writing one byte using ptrace.}
\end{figure}

Registers are similar to a memory in regards to how to read them. Linux
contains a predefined structure \texttt{user\_regs\_struct}, which maps all
registers on the current architecture. The command \texttt{PTRACE\_GETREGS}
then fills up this structure with the value in registers. To save registers,
\texttt{PTRACE\_SETREGS} can be used. One has to pass the whole structure, so
if we want to modify only some registers we first need to fetch the structure,
fill the registers we want with values, and then finally use \texttt{SETREGS}.
An implementation can be seen in figure \ref{fig:set-register}, the
\texttt{get\_register} functions maps the structure members to register name.
Since the address of the current instruction to be executed is also stored in a
register, we now have access to it.

\begin{figure}\label{fig:set-register}
    \begin{minted}{c}
void set_register(pid_t pid, const char* name, uint64_t data) {
    struct user_regs_struct regs;
    ptrace(PTRACE_GETREGS, pid, NULL, &regs);
    uint64_t* reg_data = get_register(&regs, name);
    *reg_data = data;
    ptrace(PTRACE_SETREGS, pid, NULL, &regs);
}
    \end{minted}
    \caption{Linux - Setting one register using ptrace}
\end{figure}

Breakpoints are more interesting. Debuggers often allow to enable and disable a
breakpoint, so we will distinguish between setting a breakpoint and enabling
it. Setting a breakpoint just means that the debugger needs to keep track of
where the breakpoint was set and if it is enabled or disabled. Enabling a
breakpoint means writing into the program memory the debug instruction (we will
use the x86 \texttt{INT3} with opcode \texttt{0xCC}). Figure
\ref{fig:with-and-without-bp} shows how code looks with and without enabled
breakpoint. On line $2$, the opcode changes from \texttt{0x83} to
\texttt{0xCC}. Since the breakpoint is set via the \texttt{PTRACE\_POKEDATA},
which only works data blocks, one has to pad the breakpoint opcode with already
existing data. Also, the rewritten data has to be kept so that the breakpoint
may later be deactivated. Abbreviated implementation can be found on
\ref{fig:breakpoint-enable}.

\begin{figure}\label{fig:with-and-without-bp}
    \begin{minipage}{0.45\textwidth}
        \begin{lstlisting}
c7 45 fc 05 00 00 00 	MOVL
83 7d fc 00          	CMPL
7e 07                	JLE
        \end{lstlisting}
    \end{minipage}
    \begin{minipage}{0.45\textwidth}
        \begin{lstlisting}
c7 45 fc 05 00 00 00 	MOVL
cc 7d fc 00          	INT3
7e 07                	JLE
        \end{lstlisting}
    \end{minipage}
    \caption{Code with and without breakpoint.}
\end{figure}

\begin{figure}\label{fig:breakpoint-enable}
    \begin{minted}{c}
void enable(pid_t pid, struct breakpoint* bp) {
    if (bp->enabled) {
        return;
    }
    bp->backup = read_memory(pid, bp->address);
    write_memory(pid, bp->address, BP_OPCODE);
    bp->enabled = true;
}

void disable(pid_t pid, struct breakpoint* bp) {
    if (!bp->enabled) {
        return;
    }
    write_memory(pid, bp->address, bp->backup);
    bp->enabled = false;
}
    \end{minted}
    \caption{Enabling breakpoints, abbr.}
\end{figure}

When a breakpoint is hit, the control is passed to the debugger, at this point,
the instruction pointer would point to the next instruction, which has opcode
\texttt{0x7D}, not \texttt{7E} (the \texttt{JLE} instruction) as might be
expected. This is because \texttt{INT3} is an instruction with size $1$. It
gets executed, the instruction pointer is advanced by the size ($1$) and an
interrupt is issued. But after the INT3 there were operands to the CMPL
instruction, we definitely do not want to interpret them as instruction. On
some architectures, advancing PC does not happen for the debug instruction
(like ARM \todo{Checked by hand - Reverse engineered from LLDB source code}.).

Additionally, if we just moved back and resumed the program, we would again hit
the breakpoint which is still set! We need to temporarily unset it, move one
instruction forward, and set it again. The general idea behind it can be found
in figure \ref{fig:continue}. With breakpoints, we essentially gained the
ability to single step as well. 

\begin{figure}\label{fig:continue}
    \centering
    \includegraphics[width=100mm,scale=0.5]{media/breakpoint_tbd}
    \caption{Continue sketch}
\end{figure}

We showed that the breakpoint must be put at the next instruction. This is not
as simple as it sounds. Where is the next instruction? On CISC architectures,
this is not easy to find out since instructions have different sizes. But even
on RISC architectures like ARM, what if the instruction is a jump of some sort
and the next instruction is not simply the one that follows this one in the
code? For this reason, debuggers may need to have an instruction emulator,
which needs to emulate the whole instruction set to see where the program
counter ends up\footnote{And there can be a \textit{lot} of instructions
\cite{intel-manual}}. However, some architectures offer hardware support, like
the trap flag we mentioned in section \todo{ref}.

The ptrace library contains a special \texttt{PTRACE\_SINGLESTEP} command. This
executes one instruction in the tracee and then signal \texttt{SIGTRAP} will be
sent to it. The Linux kernel (as ofv6.1.8) uses the previously mentioned trap
flag for x86 \cite{linuxkernel-trapflag}. If the architecture does not provide
a way to support single stepping then the call will return an error. If we are
on an architecture that supports this command we can use it instead of the
register dance mentioned above. Implementation is described in figure
\ref{fig:singlestep}. We presume that the instruction pointer was moved when
the breakpoint was hit, so we do not need to return one byte backward. This is
more reasonable anyway since you want to show the user at which address was the
breakpoint hit. The LLDB \cite{lldb} debugger uses hardware support if there is
one, else it uses an instruction emulator. For example for the ARM
architecture, LLDB uses an instruction emulator. All instructions are of the
same length, however, some jump or another program counter modifier could cause
the next instruction to be executed is not necessarily the following one in the
code.

\begin{figure}\label{fig:singlestep}
    \begin{minted}{c}
void step_over_bp(pid_t pid) {
    uint64_t loc = read_register(pid, "rip");
    struct breakpoint* bp = find_bp(loc);
    if (bp == NULL || !bp->enabled) {
        return;
    }

    disable(pid, bp);
    ptrace(PTRACE_SINGLESTEP, pid, NULL, NULL);
    // Waits until debugee finishes singlestepping
    wait_for_debugee(pid);
    enable(pid, bp);
}
    \end{minted}
    \caption{Stepping over breakpoint, abbreviated.}
\end{figure}

For a normal single step, we can just use the \texttt{PTRACE\_SINGLESTEP}
command. We however need to check if the current line doesn't have a
breakpoint, since that would cause the debugger to return the program counter
back before it and we wouldn't be able to step over it. So, if there is a
breakpoint use the code from \texttt{fig:singlestep}, else just use
\texttt{PTRACE\_SINGLESTEP}.

Step over is more entertaining. It is used to jump out of the current function.
When a procedure is entered using the \texttt{call} instruction, the address
immediately after the call instruction is put onto the stack. Then, on entry to
the function, \texttt{rbp} register is pushed onto the stack and then the value
of it is set to the current value of the stack pointer. So the return address
is located at \texttt{rbp + 8}. We can set a breakpoint at that address and
then continue execution, wait for the debugee to hit the breakpoint, and then
disable and remove it. This has its flaws, for example, it won't work if the
step out is used before the rbp is set. Or if some library completely bypasses
the call instruction.

This concludes the implementation of a very basic assembly level debugger for
Linux on the x86 platform. The proof of concept implementation is provided as
an extension to this thesis and can be found under \todo{\texttt{<path to the
debugger>}}. The implementation was partially inspired by
\cite{linux-debugger-blog} and \cite{lldb}.

\subsubsection*{Hardware versus Software breakpoints}
The breakpoints we have implemented here are called \textit{software
breakpoints}. In section \todo{ref} we mentioned that CPU also supports
breakpoints, these are called \textit{hardware breakpoints}. The difference
between these two are mostly felt when doing reverse engineering, where people
study compiled programs in machine code because they do not have an access to
source code of the programs. This is done to find out what the program does,
for example to find out if it is of malicious nature. The programs themselves
however often try to defend from being debugged. Software breakpoints changes
the actual code, so a checksum of instruction opcodes can detect them. Hardware
breakpoints on the other hand do not touch the code, so they cannot be detected
as easily. They can also be used to break on memory access, which is not
possible with software breakpoints. However, we can only have limited number of
hardware breakpoints (4 on x86).

\todo{Describe how LLDB does things?}

\subsection{UNIX systems}
There are other systems based on UNIX, however the implementation is very similar to the Linux one.
For example, MacOS, FreeBSD and OpenBSD also have the \texttt{ptrace} system call. The function is
little different on each operating system but it can be used to achieve the same functionality as
on the linux operating system.

\subsection{Windows}
\todo{WIP: Will be rewritten (probably shortened)}
Windows also has built-in support for debugging at the Win32API layer
\cite{windows-msdn-debugging-api, windows-press-debugging-api}. It builds on
\textit{debug events} and \textit{debug functions}. Summary of some of the
functions that Win32 API offers which all help with debugging:

\begin{itemize}
    \item \mintinline{c}{DebugActiveProcess} - Attaches the debugger to an
        active process.
    \item \mintinline{c}{DebugBreakProcess} - Causes a breakpoint exception to
        occur in the specified process. This passes control of the process to
        the debugger if there is one.
    \item \mintinline{c}{WaitForDebugEvent} - Waits for new debug events.
    \item \mintinline{c}{ContinueDebugEvent} - Continue the process execution
        after processing debug event.
    \item \mintinline{c}{OutputDebugString} - Sends a string to the debugger
        for display.
    \item \mintinline{c}{ReadProcessMemory} and
        \mintinline{c}{WriteProcessMemory} - Read and modify
          process virtual address space.
    \item \mintinline{c}{FlushInstructionCache} - Flushes instruction cache of
        the process.
\end{itemize}

The general structure of Windows debugger can be seen in figure
\ref{fig:win32debugger}. The debugger waits for debug events via function
\mintinline{c}{WaitForDebugEvent}. This function has a timeout parameter, so
the debugger can also do other things while it's waiting, like react to GUI
interaction.
\begin{figure}
    \centering
    \scalebox{0.8}{
    \begin{tikzpicture}
        \draw (-7,0) -- (-7,-11) (0,0) -- (0,-11) (7,0) -- (7,-11);
        \node at (-7,.3) {Debugee};
        \node at (0,.3) {Win32 API};
        \node at (7,.3) {Debugger};
        \draw[<-] (0,-1) -- node[midway,above] {\mintinline{c}{CreateProcess}} (7,-1);
        \draw[<-] (-7,-2) -- node[midway,above] {Create} (0,-2);
        \draw[->] (0,-3) -- node[midway,above] {\mintinline{c}{CreateProcess} returns} (7,-3);
        \draw[<-] (0,-5) -- node[midway,above] {\mintinline{c}{ContinueDebugProcess}} (7,-5);
        \draw[<-] (0,-6) -- node[midway,above] {\mintinline{c}{WaitForDebugEvent}} (7,-6);
        \draw[dashed,->] (-7,-6.5) -- node[midway,above] {Exception} (0,-6.5);
        \draw[->] (0,-7) -- node[midway,above] {\mintinline{c}{WaitForDebugEvent} returns \texttt{true}} (7,-7);
        \draw[dashed, <-] (-7, -8) -- node[above left] {Debugger actions} (7, -8);
        \draw[<-] (0,-9) -- node[midway,above] {\mintinline{c}{ContinueDebugProcess}} (7,-9);
        \draw[<-] (0,-10) -- node[midway,above] {\mintinline{c}{WaitForDebugEvent}} (7,-10);
        \draw[dashed,->] (-7,-10.5) -- node[midway,above] {Exception} (0,-10.5);
    \end{tikzpicture}
    }
    \caption{A sequence diagram for debugger using Windows api. Inspired by \todo{NI-REV 6. lecture}}
    \label{fig:win32debugger}
\end{figure}

\subsubsection*{Debug Events}\label{section:Debug Events}
Debugging events are various incidents in the debuggee that causes the system
to notify the debugger \cite{windows-msdn-debug-events}. These are stored in
special \mintinline{c}{DEBUG_EVENT} structure, which is received in
\texttt{WaitForDebugEvent} call from debugger. This structure contains various
information about the event, the internals can be seen on figure
\ref{fig:DebugEvent}. These events include loading and unloading a DLL,
creating and exiting a process, sending debug strings via the
\mintinline{c}{OutputDebugString} and so on. One category of events
are exceptions, lets look at them more closely.

\begin{figure}
\begin{minted}{c}
typedef struct _DEBUG_EVENT {
  DWORD dwDebugEventCode;
  DWORD dwProcessId;
  DWORD dwThreadId;
  union {
    EXCEPTION_DEBUG_INFO      Exception;
    CREATE_THREAD_DEBUG_INFO  CreateThread;
    CREATE_PROCESS_DEBUG_INFO CreateProcessInfo;
    EXIT_THREAD_DEBUG_INFO    ExitThread;
    EXIT_PROCESS_DEBUG_INFO   ExitProcess;
    LOAD_DLL_DEBUG_INFO       LoadDll;
    UNLOAD_DLL_DEBUG_INFO     UnloadDll;
    OUTPUT_DEBUG_STRING_INFO  DebugString;
    RIP_INFO                  RipInfo;
  } u;
} DEBUG_EVENT, *LPDEBUG_EVENT;
\end{minted}
\caption{Structure which contains info about debug event.}
\label{fig:DebugEvent}
\end{figure}

\subsubsection*{Structured Exception Handling}
On POSIX systems, abnormal conditions which need immediate attention are
handled via signals \todo{ref signals}. Windows however is not a POSIX system.
Instead, Windows uses \textit{Structured Exceptions} \cite{windows-msdn-seh}.
From now on, we will be using the abbreviation 'SEH'. An exception is an event
that requires execution of code outside the normal flow of control. There are
software exceptions, like throwing an exception explicitly or by OS, and
hardware exceptions, like the division by zero we mentioned. Instruction with
opcode \mintinline{c}{0xCC}, which is used for breakpoints, will also raise an
exception. SEH unifies both of these things into one just like signals do.

When an exception is triggered, control is transferred to the system. It saves
the state of the thread and some other information. This information can be
used to continue execution from the point where the exception was thrown when
it is resolved. It also contains information about which type of exception was
thrown, if execution can continue after handling the exception, address where
the exception occured and some others\footnote{See MSDN documentation
\cite{windows-msdn-seh} for full detailed list}. The system then searches for
an exception handler which will handle the exception. The search is performed
in this order:

\begin{enumerate}
    \item If the process is debugged the debugger is notified.
    \item If the process is not debugged or the debugger does not handle the
        exception, the frame-based exception handler is to be
        found\footnote{The handlers are not very important to us, see MSDN
        documentation if you're interested \cite{windows-msdn-seh}.}
    \item If no frame-based handler can be found, or no handler handles the
        exception, but the process is being debugged then the debugger gets
        notified once again.
    \item The system provides default handler, which often is termination of
        the program via \mintinline{c}{ExitProcess}.
\end{enumerate}

The debugger has two opportuinites to handle the exception. The
\textit{first-chance} is before the exception gets to the debugee. This is
intended for exceptions for which the debugger is responsible, for example
breakpoint or single stepping. The debugger should handle these. The second
opportunity, called \textit{last-chance}, is when a debugee doesn't have
appropriate frame-based handler to handle the exception. If the debugger
weren't in the way, system would have already used the default exception
handler, which is often program termination. This gives us a last chance to
look at the state of the program before it will be killed
\cite{windows-msdn-dbg-exc-handling}.

Examples of some exceptions that tie into debugging:
\begin{itemize}
    \item \texttt{EXCEPTION\_BREAKPOINT} - Raised when a hardware-defined
        breakpoint was encountered. This includes the mentioned
        \texttt{INT3} instruction.
    \item \texttt{EXCEPTION\_SINGLE\_STEP} - Raised when a hardware supported
        single step was completed.
\end{itemize}

\subsubsection*{Tying it all together}
We presented various functions that offer debugging support. The implementation
itself would be very similar to the Linux one we presented in section
\todo{ref}. For illustration, in figure \ref{fig:windows-debugger-mainloop} is
shown an abbreviated main loop of the debugger. We not only need to handle
exception debug events but others also if we want our debugger to be robust.
For example thread creation might interest us too, so that we can trace all
threads of the debugee.

\begin{figure}\label{fig:windows-debugger-mainloop}
    \begin{minted}{c}
void EnterDebugLoop(const LPDEBUG_EVENT DebugEv)
{
   DWORD dwContinueStatus = DBG_CONTINUE; // exception continuation
   for(;;)
   {
      WaitForDebugEvent(DebugEv, INFINITE);
      switch (DebugEv->dwDebugEventCode)
      {
          case EXCEPTION_DEBUG_EVENT:{
            // Handle exception debug events
            ...
          }
          // Other debug events
          ...
      }
   ContinueDebugEvent(DebugEv->dwProcessId,
                      DebugEv->dwThreadId,
                      dwContinueStatus);
   }
}
    \end{minted}
    % Beware, this figure is cursed. Adding caption here will break the entire
    % build for god knows what stupid reason.
\end{figure}

\section{Compilers}
The compiler is a program which transforms the source code into some other
form, most often into machine code or assembly. Compilers are very complicated
piece of software. Often, they are made of several parts, the general structure
can be seen in figure \ref{fig:compiler-structure} \cite{dragon-book}. We will
briefly explore these stages.

\tikzstyle{compilerblock} = [rectangle, draw, minimum width=6cm, minimum height=1cm] 
\tikzstyle{tables} = [rectangle, draw, minimum width=4cm, minimum height=1cm] 
\begin{figure}\label{fig:compiler-structure}
    {\centering
    \begin{tikzpicture}
    \node (lexer)[compilerblock]{Lexical analyzer};
    \node (syntax)[compilerblock,below=of lexer]{Syntactic analyzer};
    \node (semantic)[compilerblock,below=of syntax]{Semantic analyzer};
    \node (imc)[compilerblock,below=of semantic]{Intermediate Code Generator};
    \node (gen)[compilerblock,below=of imc]{Code Generator};
    \node (symbol)[tables, left=of semantic]{Symbol table};
    \draw[->] (lexer) -- node[below] {} (syntax);
    \draw[->] (syntax) -- node[below] {} (semantic);
    \draw[->] (semantic) -- node[below] {} (imc);
    \draw[->] (imc) -- node[below] {} (gen);
    \end{tikzpicture} 
    \par}
    \caption{Simplified structure of a compiler. Some parts were left out, like
    optimizations.}
    \label{fig:compiler_tikz}
\end{figure}

\subsection{Lexical analyzer}
The lexical analyzer groups separate symbols into groups. For example the code
\begin{minted}{c}
foo = bar(1 + 2);
\end{minted}
might be translated into tokens like this
\begin{lstlisting}[stringstyle=\color{black}]
<id:"foo"> <assignment-operator> <id:"bar"> 
<left-bracket> <int-number:1> <plus-operator> 
<int-number:2> <right-bracket> <semicolon>
\end{lstlisting}
The Syntactic analyzer then works with these tokens.

\subsection{Syntantic and semantic analyzer}
Syntactic analysis accepts tokens and processes them into other intermediate
representation. This is most often an abstract syntax tree (abbr. AST, figure
\ref{fig:ast}). It also checks that the source code complies to the grammar of
the language. Semantic analysis then checks that the program is semantically
consistent. For example that used variable has been declared before.

\begin{figure}\label{fig:ast}
    \centering
    \begin{tikzpicture}[,shorten >=1pt,node distance=1.8cm,on grid,initial/.style={}]
    \node (assignment) {$=$};
    \node (foo) [below left =of assignment] {id:foo};
    \node (bar) [below right =of assignment] {call:bar};
    \node (plus) [below right=of bar] {$+$};
    \node (one) [below left =of plus] {$1$};
    \node (two) [below right =of plus] {$2$};
    
    \draw[-, above, scale=0.7] 
    (assignment)   edge node[scale=0.7, left, yshift=0.1cm] {lhs}  (foo)
     (assignment)  edge node[scale=0.7, right, yshift=0.1cm] {rhs}  (bar)
     (bar)         edge node[scale=0.7, right, yshift=0.1cm] {expr} (plus)
     (plus)        edge node[scale=0.7, right, yshift=0.1cm] {rhs}  (two)
     (plus)        edge node[scale=0.7, left, yshift=0.1cm] {lhs}  (one);
    \end{tikzpicture}
    \caption{Simplified example of an abstract syntax tree.}
    \label{fig:astgraph}
\end{figure}
 
\subsection{Intermediate code generation}
This part converts AST into some other representation, most commonly called IR,
which means intermediate representation. IR is closer to machine code, to be
easily translated, but retain some high level properties that makes it easier
to work with it, like types and functions. There are many types of IR. One of
the most popular compilers, LLVM, uses single static assignment (SSA)
\cite{llvm}. Example of LLVM IR can be found on figure
\ref{fig:llvm-ir-example}. Compilers perform most optimizations on this
intermediate representation. 

\begin{figure}\label{fig:llvm-ir-example}
    \begin{minted}{llvm}
        define dso_local i32 @_Z6squarei(i32 %0) {
          %2 = alloca i32, align 4
          store i32 %0, i32* %2, align 4
          %3 = load i32, i32* %2, align 4
          %4 = load i32, i32* %2, align 4
          %5 = mul nsw i32 %3, %4
          ret i32 %5
        }
    \end{minted}
    \caption{Simplified example of LLVM IR.}
\end{figure}

\subsection{Code generation}
Here, IR is translated directly to the target machine code or possibly
assembly. Even though IR can seem very similar to assembly, there are still
some things to take care of. For example SSA IR doesn't have registers, it uses
unlimited number of variables. Other architectures might have some other traits
that differ it from the IR and they all have to be accounted for when
generating code.

\subsection{Modularity of compilers}
The main advantage of using an IR is that there is a common ground for every
language. Imagine we write a compiler for the C language. We need to write all
five parts from figure \ref{fig:compiler-structure}. If we later decided that
we also want to create a compiler for Haskell, we just need to write everything
up to the IR translation. Once we can translate Haskell into the IR, we can
reuse the previous part of the compiler to compile to machine code! This also
works the other way around. If we compiled IR to the machine code that works
with the x86 architecture, and we want to compile to ARM, we just need to
create the code generation part for the ARM architecture, no need to write
whole compiler. Also, most of the optimizations are done on the IR level, this
also saves a lot of development time. The parts of the compiler which are
dependent on the source language are called \textbf{frontend} (Syntax, Semantic
and IR translation), the parts that are dependent on the target are called
\textbf{backend} (Code generation).

This is widely used in practice. The LLVM \cite{llvm} project is a compiler
backend. It uses its own IR (as was mentioned on figure
\ref{fig:llvm-ir-example}). It can compile this IR into many targets, including
x86, ARM and Spark. The \textit{Clang} project is a compiler frontend for C,
C++ and Objective-C languages. It translates these languages to the LLVM IR.
Other frontends for LLVM also include \textit{ghc}, which is a Haskell
compiler, or \textit{rustc}, which is a Rust compiler. With LLVM, creating new
programming language comes down to parsing it into an AST and transforming that
AST into the LLVM IR.

\subsection{Interpreting programs}
\todo{Consider throwing away.}
Not all languages are translated to machine code. Sometimes an interpreter is
created, which is a program that reads the source code but instead of compiling
it into machine code it just runs it\footnote{In reality those languages are
often compiled into bytecode, which is interpreted.}. Dynamically typed
languages tend to be interpreted, but it is not a rule. Some languages have
both compiler and interpreter, like Haskells GHC. Since the interpreter is a
program, it is another layer of abstraction. This can make the resulting
language more abstract then the compiled ones, sometimes at the cost
of performance~\cite{jit}. 

\section{Debug information}
If we want to debug at the source code level, we need to give the debugger some
information, because otherwise it can only work with the generated machine
code. For example, we somehow need to provide information to the debugger that
instruction at address $0xABCD$ belongs to line $x$ in the source code. Or we
need to provide information where is some variable located. Before we get into
that, we will take a look at the layout of executables and where are those
informations stored.

\subsection{ELF}
ELF means Executable and Linkable format, it is a format used for binary
applications. The file itself consist of sections, some of these are
\begin{itemize}
    \item .text - the executable code,
    \item .data - allocated space and values of initialized static\footnote{In
        this context, static means that the variable exists for the entire
        lifetime of the program} variables and other objects,
    \item .bss - allocated space for unitialized static variables,
    \item .rodata - data that doesn't change for the entirety of the program
        lifetime, like strings literals in C.
    \item various debug sections like .debug\_info, .debug\_line etc.
\end{itemize}
For inspecting the ELF files, commands \texttt{readelf} and \texttt{objdump}
may be used on Linux systems. The ELF format also has a header, and all
sections have their header too. This contains information like name of the
section, size of the section etc. The ELF format are mainly used for
\textit{relocatable} file, \textit{executable} file and \textit{shared object}
file \cite{elf}. We will talk only about the executable, since that is most
relevant to us. The sections themselves are often protected. For example, the .text section
can only be read and executed, but cannot be written to. The .data section
can be read and written to, but cannot be executed.

\subsection{DWARF}
DWARF\footnote{The name DWARF is a pun, since it was developed alongside ELF.}
is a debugging format used to describe programs written in procedural
languages. It is primarily associated with ELF. It aims to support all
different information which may be needed while debugging. This makes it
complex, we will not discuss everything DWARF has to offer but the most basic
features that are useful for almost any language.

\subsubsection{Line Number Information}
Line number information needs to convey which line of code corresponds to an
address of machine code instruction. The DWARF standard \cite{dwarf} mentions
that encoding this information would be possible in a matrix, which would have
one row for each instruction. The columns of the matrix would contain
\begin{itemize}
    \item the source file name,
    \item the source line number,
    \item the source column number,
    \item whether this instruction is the beginning of a source statement,
    \item whether this instruction is the beginning of a basic
        block\footnote{Basic block is a sequence of instructions that is
        entered only at the first instruction and exited only at the last
        instruction \cite{dwarf}. In other words, all of the instructions in
        the basic block are executed sequentially.}
\end{itemize}
They however argue that such a matrix would be very big. The matrix is then
stripped of redundant information, for example instruction whose location is
the same as the previous one is removed. Instead of a matrix, they provide a
bytecode language which one has to interpret to gain this information. The
bytecode program is then encoded in the executable and one can build the 
matrix from this bytecode program.

The virtual machine consists of registers \texttt{address}, \texttt{file},
\texttt{line}, \texttt{column}, \texttt{is\_stmt}, \texttt{basic\_block}, and
\texttt{end\_sequence}. The program itself begins with a prologue. This
prologue contains length of the program, version, length of the prologue,
length of instructions (so that it may be better compressed) and similar
informations. Then \textit{Standard opcodes} are provided, which are
instructions of the virtual machine. These are mostly used for manipulating the
registers of the machine or to create a row from the values in the registers
and append it to the matrix. 

It also has \textit{Special opcodes}, they affect the virtual machine in the following way:
\begin{itemize}
    \item Add a signed integer to the \texttt{line} register.
    \item Multiply an unsigned integer by the smallest length of an instruction and add the result to the \textit{address} register.
    \item Append a row to the matrix consisting of the current values in registers.
    \item Set the \texttt{basic\_block} register to false.
\end{itemize}
All of these opcodes do those four things, they only differ in what values they
add to the \texttt{line} and \texttt{address} register \cite{dwarf}. Those
values are calculated from the instruction opcode, which ranges from $10$ to
$255$ in DWARF version 2. 

Observe program in figure \ref{fig:c-program-and-its-assembly}. A simple
greeter-like program which displays the name given to it as an argument. With
the \texttt{readelf} utility program, we can inspect the DWARF bytecode
language describing the locations, it is showed in figure
\ref{fig:dwarf-locations}. It sets the address to the beginning of the
\texttt{main} function and then saves it to the matrix with the special opcode
instruction. Next, it skips all the way to \texttt{cmpl} at address
\texttt{1148} instruction because that is the start of the \texttt{if}
statement on line $4$ and saves that to the matrix. Since the opcodes take up
one byte this technique is very efficient on space, that is why DWARF uses it.
This information is stored in the section \texttt{.debug\_line}.

\begin{figure}\label{fig:c-program-and-its-assembly}
    \begin{minted}{c}
#include <stdio.h>

int main(int argc, char* argv[]) {
    if (argc < 1) {
        return 1;
    }

    printf("Hello, %s\n!", argv[1]);
    return 0;
}
    \end{minted}
    \begin{lstlisting}
0000000000001139 <main>:
1139:	55                   	push   %rbp
113a:	48 89 e5             	mov    %rsp,%rbp
113d:	48 83 ec 10          	sub    $0x10,%rsp
1141:	89 7d fc             	mov    %edi,-0x4(%rbp)
1144:	48 89 75 f0          	mov    %rsi,-0x10(%rbp)
1148:	83 7d fc 00          	cmpl   $0x0,-0x4(%rbp)
114c:	7f 07                	jg     1155 <main+0x1c>
114e:	b8 01 00 00 00       	mov    $0x1,%eax
1153:	eb 27                	jmp    117c <main+0x43>
1155:	48 8b 45 f0          	mov    -0x10(%rbp),%rax
1159:	48 83 c0 08          	add    $0x8,%rax
115d:	48 8b 00             	mov    (%rax),%rax
1160:	48 89 c6             	mov    %rax,%rsi
1163:	48 8d 05 9a 0e 00 00 	lea    0xe9a(%rip),%rax
116a:	48 89 c7             	mov    %rax,%rdi
116d:	b8 00 00 00 00       	mov    $0x0,%eax
1172:	e8 b9 fe ff ff       	call   1030 <printf@plt>
1177:	b8 00 00 00 00       	mov    $0x0,%eax
117c:	c9                   	leave
117d:	c3                   	ret
    \end{lstlisting}
    \caption{A program in C and corresponding program in assembly.}
\end{figure}

\begin{figure}\label{fig:dwarf-locations}
    \begin{lstlisting}
Extended opcode 2: set Address to 0x1139
Special opcode 7: advance Address by 0 to 0x1139 and Line by 2 to 3
Set column to 8
Special opcode 216: advance Address by 15 to 0x1148 and Line by 1 to 4
Set column to 16
Special opcode 90: advance Address by 6 to 0x114e and Line by 1 to 5
Set column to 32
Special opcode 106: advance Address by 7 to 0x1155 and Line by 3 to 8
Set column to 5
Special opcode 117: advance Address by 8 to 0x115d and Line by 0 to 8
Set column to 12
Advance PC by constant 17 to 0x116e
Special opcode 132: advance Address by 9 to 0x1177 and Line by 1 to 9
Set column to 1
Special opcode 76: advance Address by 5 to 0x117c and Line by 1 to 10
Advance PC by 2 to 0x117e
Extended opcode 1: End of Sequence
    \end{lstlisting}
    \caption{An DWARF description of mapping source lines to addresses for program in figure \ref{fig:c-program-and-its-assembly}.}
\end{figure}

\subsubsection{Debugging Information Entry}
The \textit{Debugging Information Entries}, or DIEs, are the building block of
debugging information in DWARF. Each DIE has a tag and series of attributes.
The tag specifies the class to which entry it belongs, like
\texttt{DW\_TAG\_subprogram}, which is used for functions, or
\texttt{DW\_TAG\_variable}, which is used for variables. Complete list can be
found in \cite{dwarf}. Those entries can be found in \texttt{.debug\_info}
section \cite{dwarf}.

The attributes themselves then convey some property of the DIE, like name and
type of a variable or starting and ending address of a function. The DIEs form
a tree like structure. Each DIE is owned by one parent (excluding the top DIE)
and can own multiple DIEs. There are also other relations among the DIEs, not
only ownership. With those relations in place the relation is a graph, not just
a tree.

\subsubsection{Locations of variables}
\todo{todo.}

